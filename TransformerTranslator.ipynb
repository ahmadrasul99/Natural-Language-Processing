{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import math\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/'\n",
    "train_urls = ('train.de', 'train.en')\n",
    "val_urls = ('newstest2015.de', 'newstest2015.en')\n",
    "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
    "train_urls = ('train.de.gz', 'train.en.gz')\n",
    "val_urls = ('val.de.gz', 'val.en.gz')\n",
    "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = [download_from_url(url_base + url) for url in train_urls]\n",
    "val_filepaths = [download_from_url(url_base + url)[0] for url in val_urls]\n",
    "test_filepaths = [download_from_url(url_base + url)[0] for url in test_urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.data/train.de', '.data/train.en']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
    "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
    "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filepath,tokenizer):\n",
    "    counter = Counter()\n",
    "    with io.open(filepath,encoding=\"utf8\") as f:\n",
    "        for string_ in f:\n",
    "            counter.update(tokenizer(string_))\n",
    "    return Vocab(counter,specials=['<unk>','<pad>','<sos>','<eos>'])\n",
    "de_vocab = build_vocab(train_filepaths[0],de_tokenizer)\n",
    "en_vocab = build_vocab(train_filepaths[1],en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19215"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-51cbc1469d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mde_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_filepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mde_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0men_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_filepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0men_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-51cbc1469d54>\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(filepath, tokenizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstring_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '.'"
     ]
    }
   ],
   "source": [
    "def build_vocab(filepath,tokenizer):\n",
    "    counter = Counter()\n",
    "    with io.open(filepath,encoding=\"utf8\") as f:\n",
    "        for string_ in f:\n",
    "            counter.update(tokenizer(string_))\n",
    "    return Vocab(counter,specials=['<unk>','<pad>','<sos>','<eos>'])\n",
    "de_vocab = build_vocab(train_filepaths[0],de_tokenizer)\n",
    "en_vocab = build_vocab(train_filepaths[1],en_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(filepaths):\n",
    "    raw_de_itr = iter(io.open(filepaths[0],encoding=\"utf8\"))\n",
    "    raw_en_itr = iter(io.open(filepaths[1],encoding=\"utf8\"))\n",
    "    data =[]\n",
    "    for(raw_de,raw_en) in zip(raw_de_itr,raw_en_itr):\n",
    "        de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],dtype=torch.long)\n",
    "        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
    "                            dtype=torch.long)\n",
    "        data.append((de_tensor_, en_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<sos>']\n",
    "EOS_IDX = de_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    src_pad_masks,tgt_pad_masks = [],[]\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(en_item)\n",
    "    de_batch = pad_sequence(de_batch, batch_first=True,padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, batch_first=True,padding_value=PAD_IDX)\n",
    "    for en_item in en_batch:\n",
    "        curr_mask = en_item == PAD_IDX\n",
    "        src_pad_masks.append(curr_mask)\n",
    "    src_pad_masks = torch.stack(src_pad_masks)\n",
    "    for de_item in de_batch:\n",
    "        curr_mask = torch.logical_or(de_item == PAD_IDX,de_item == EOS_IDX)[:-1]\n",
    "        tgt_pad_masks.append(curr_mask)\n",
    "    tgt_pad_masks = torch.stack(tgt_pad_masks)\n",
    "    return en_batch,de_batch,src_pad_masks,tgt_pad_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch,num_workers=4)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch,num_workers=4)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_batch,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_nopeek_mask(length):\n",
    "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "    return mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTranlator(nn.Module):\n",
    "    def __init__(self,in_token,out_token,ninp,nhead,nhid,nlayers,dropout=0.5):\n",
    "        super(TransformerTranlator, self).__init__()\n",
    "        self.ninp = ninp\n",
    "        self.encoder_embedding = nn.Embedding(in_token,ninp)\n",
    "        self.decoder_embedding = nn.Embedding(out_token,ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp,dropout)\n",
    "        self.transformer = nn.Transformer(d_model=ninp,nhead=nhead,num_encoder_layers=nlayers,num_decoder_layers=nlayers,dim_feedforward=nhid,dropout=dropout)\n",
    "        self.fc = nn.Linear(ninp,out_token)\n",
    "        \n",
    "    def generate(self,out):\n",
    "        output = rearrange(out,'t n e -> n t e')\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self,src,src_pad_mask,tgt,tgt_mask,tgt_pad_mask,mem_mask):\n",
    "        src = self.encoder_embedding(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        src = rearrange(src,'n s e-> s n e')\n",
    "        \n",
    "        tgt = self.decoder_embedding(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        tgt = rearrange(tgt, 'n t e-> t n e')\n",
    "        \n",
    "        out = self.transformer(src=src,src_key_padding_mask=src_pad_mask,tgt=tgt,tgt_mask=tgt_mask,tgt_key_padding_mask=tgt_pad_mask,memory_key_padding_mask=mem_mask)\n",
    "        return self.generate(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "in_token = len(en_vocab)\n",
    "out_token = len(de_vocab)\n",
    "\n",
    "emsize = 768\n",
    "nhid = 256\n",
    "nlayers = 6\n",
    "nhead = 6\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerTranlator(in_token,out_token,emsize,nhead,nhid,nlayers,dropout).to(device)\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i,(en_batch,de_batch,src_pad_masks,tgt_pad_masks) in enumerate(valid_iter):\n",
    "            en_batch = en_batch.to(device)\n",
    "            de_batch = de_batch.to(device)\n",
    "            src_pad_masks = src_pad_masks.to(device)\n",
    "            tgt_pad_masks = tgt_pad_masks.to(device)\n",
    "            optim.zero_grad()\n",
    "            tgt_in = de_batch[:,:-1]\n",
    "            tgt_out = de_batch[:,1:]\n",
    "\n",
    "            tgt_mask = gen_nopeek_mask(tgt_in.shape[1]).to(device)\n",
    "            mem_pad_mask = src_pad_masks.clone()\n",
    "\n",
    "            output = model(en_batch,src_pad_masks,tgt_in,tgt_mask,tgt_pad_masks,mem_pad_mask)\n",
    "            loss = criterion(rearrange(output, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "            total_loss += loss.item()\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        curr_loss = total_loss / len(valid_iter)\n",
    "        print(\"Eval Epoch: {:d} Loss: {:.2f} | Batches/sec: {:.2f}\".format(epoch,curr_loss,len(valid_iter) / elapsed))\n",
    "        writer.add_scalar('Evaluation Loss',curr_loss,epoch)\n",
    "        writer.add_scalar('Evaluation Speed',len(valid_iter)/elapsed,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,writer,epochs):\n",
    "    log_interval = 100\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    num_batch = len(train_iter)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: \",epoch)\n",
    "        model.train()\n",
    "        for i,(en_batch,de_batch,src_pad_masks,tgt_pad_masks) in enumerate(train_iter):\n",
    "            en_batch = en_batch.to(device)\n",
    "            de_batch = de_batch.to(device)\n",
    "            src_pad_masks = src_pad_masks.to(device)\n",
    "            tgt_pad_masks = tgt_pad_masks.to(device)\n",
    "            optim.zero_grad()\n",
    "            tgt_in = de_batch[:,:-1]\n",
    "            tgt_out = de_batch[:,1:]\n",
    "\n",
    "            tgt_mask = gen_nopeek_mask(tgt_in.shape[1]).to(device)\n",
    "            mem_pad_mask = src_pad_masks.clone()\n",
    "\n",
    "            output = model(en_batch,src_pad_masks,tgt_in,tgt_mask,tgt_pad_masks,mem_pad_mask)\n",
    "            loss = criterion(rearrange(output, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "            total_loss += loss.detach().item()\n",
    "            if(i % log_interval == 0 and i != 0):\n",
    "                elapsed = time.time() - start_time\n",
    "                total_batches = epoch*len(train_iter) + i\n",
    "                curr_loss = total_loss / log_interval\n",
    "                print(\"Training Loss: {:.2f} | Batches/sec: {:.2f} | Total batches: {:d}\".format(curr_loss,log_interval / elapsed,total_batches))\n",
    "                \n",
    "                writer.add_scalar('Training Loss',curr_loss,total_batches)\n",
    "                writer.add_scalar('Training Speed',log_interval/elapsed,total_batches)\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        evaluate(model,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Training Loss: 4.50 | Batches/sec: 1.75 | Total batches: 100\n",
      "Training Loss: 3.51 | Batches/sec: 1.88 | Total batches: 200\n",
      "Eval Epoch: 0 Loss: 3.01 | Batches/sec: 4.49\n",
      "Epoch:  1\n",
      "Training Loss: 4.03 | Batches/sec: 1.40 | Total batches: 327\n",
      "Training Loss: 2.99 | Batches/sec: 1.82 | Total batches: 427\n",
      "Eval Epoch: 1 Loss: 2.73 | Batches/sec: 4.51\n",
      "Epoch:  2\n",
      "Training Loss: 3.65 | Batches/sec: 1.38 | Total batches: 554\n",
      "Training Loss: 2.83 | Batches/sec: 1.84 | Total batches: 654\n",
      "Eval Epoch: 2 Loss: 2.52 | Batches/sec: 4.42\n",
      "Epoch:  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b771ac472214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurrTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d%m%Y%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mcurrTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-557cd150110c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, writer, epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "currTime = datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "writer = SummaryWriter('runs/'+ currTime)\n",
    "train(model,writer,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
